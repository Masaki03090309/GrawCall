# M2.3 完了レポート: AIプロンプトアシスタント

**完了日**: 2025-01-05
**マイルストーン**: M2.3 - AIプロンプトアシスタント
**ステータス**: ✅ 完了

---

## 実装概要

M2.3では、音声録音からAIが自動的にプロンプトを生成する機能を実装しました。ユーザーは理想的な営業通話の内容を音声で録音するだけで、AIがそれを分析して最適なフィードバック生成用プロンプトを作成します。

### 実装した機能

1. **音声録音UI（Web Audio API）**
   - リアルタイム録音時間表示
   - 録音インジケーター（アニメーション付き）
   - 最大録音時間制限（デフォルト5分）
   - 録音後の音声プレビュー再生
   - マイクアクセス許可フロー

2. **Whisper API連携**
   - 音声ファイル（WebM形式）を自動文字起こし
   - 日本語認識対応
   - Base64エンコーディング対応

3. **GPT-4o連携（プロンプト生成）**
   - 文字起こしテキストから営業フィードバック用プロンプトを生成
   - システムプロンプトで営業通話分析に最適化
   - マークダウン形式で構造化されたプロンプト生成
   - 追加コンテキスト入力対応

4. **プロンプト作成ページ統合**
   - 折りたたみ可能なAIアシスタントカード
   - プロンプトタイプ別対応（connected/reception）
   - 生成されたプロンプトを自動的にエディタに挿入
   - 文字起こし結果の表示と確認
   - リアルタイムローディング状態表示

---

## 成果物

### API Routes

| ファイル                         | メソッド | 説明                                                      |
| -------------------------------- | -------- | --------------------------------------------------------- |
| `/app/api/prompts/generate`      | POST     | 音声→文字起こし→プロンプト生成の一連の処理を実行         |

### UI Components

| ファイル                                                  | 説明                                                |
| --------------------------------------------------------- | --------------------------------------------------- |
| `components/AudioRecorder.tsx`                            | 音声録音コンポーネント（Web Audio API使用）         |
| `/app/(dashboard)/projects/[id]/prompts/new/page.tsx`     | AIアシスタント統合済みプロンプト作成ページ          |

### Dependencies

使用しているライブラリ:

- `openai` - Whisper API、GPT-4o API連携
- `lucide-react` - アイコン（Mic, Square, Sparkles, ChevronUp/Down）
- `sonner` - トースト通知

---

## データフロー

```
┌─────────────────────────────────────────────────────────────┐
│ 1. ユーザーが音声録音                                        │
│    - Web Audio API (MediaRecorder)                           │
│    - WebM形式で録音                                          │
│    - Base64エンコーディング                                  │
└─────────────────────────────────────────────────────────────┘
                            ↓
┌─────────────────────────────────────────────────────────────┐
│ 2. POST /api/prompts/generate                                │
│    - 認証チェック（Supabase Auth）                           │
│    - Zodバリデーション                                       │
└─────────────────────────────────────────────────────────────┘
                            ↓
┌─────────────────────────────────────────────────────────────┐
│ 3. Whisper API 文字起こし                                    │
│    - Model: whisper-1                                        │
│    - Language: ja (日本語)                                   │
│    - Input: audio/webm                                       │
│    - Output: 日本語テキスト                                  │
└─────────────────────────────────────────────────────────────┘
                            ↓
┌─────────────────────────────────────────────────────────────┐
│ 4. GPT-4o プロンプト生成                                     │
│    - Model: gpt-4o                                           │
│    - System Prompt: 営業フィードバックプロンプト生成専門家   │
│    - Input: 文字起こしテキスト + 追加コンテキスト            │
│    - Output: マークダウン形式の構造化プロンプト              │
└─────────────────────────────────────────────────────────────┘
                            ↓
┌─────────────────────────────────────────────────────────────┐
│ 5. UIに結果表示                                              │
│    - 文字起こしテキスト表示                                  │
│    - 生成されたプロンプトをエディタに自動挿入                │
│    - ユーザーが編集可能                                      │
│    - 保存ボタンで通常のプロンプト作成フローへ                │
└─────────────────────────────────────────────────────────────┘
```

---

## API仕様

### POST /api/prompts/generate

**リクエスト**:

```json
{
  "audio": "data:audio/webm;base64,GkXfo59ChoEBQveBAULygQ...",
  "prompt_type": "connected",
  "additional_context": "ヒアリング力を重視したフィードバックにしてください"
}
```

**レスポンス（成功）**:

```json
{
  "success": true,
  "data": {
    "transcription": "こんにちは、〇〇会社の△△と申します。今回は...",
    "generated_prompt": "# 営業通話フィードバック生成プロンプト\n\n## 分析の観点\n...",
    "prompt_type": "connected",
    "usage": {
      "transcription_length": 253,
      "prompt_length": 542
    }
  }
}
```

**レスポンス（エラー）**:

```json
{
  "success": false,
  "error": {
    "code": "OPENAI_RATE_LIMIT",
    "message": "OpenAI APIのレート制限に達しました。しばらくしてから再試行してください。"
  }
}
```

---

## UI/UX 特徴

### AIアシスタントカード

- **折りたたみ可能**: ChevronUp/Downアイコンで開閉
- **視覚的に目立つデザイン**: 紫色のアクセントカラー
- **Sparklesアイコン**: AI機能を示唆
- **段階的な情報表示**: 録音→文字起こし→プロンプト生成の流れが明確

### 音声録音コンポーネント

- **録音前**: 「音声を録音」ボタン（マイクアイコン付き）
- **録音中**:
  - 赤色の点滅インジケーター
  - リアルタイム録音時間（MM:SS形式）
  - 「停止」ボタン（赤色、Squareアイコン）
- **録音後**:
  - 音声プレビュー再生コントロール
  - 録音時間表示
  - 再録音可能

### ローディング状態

- **文字起こし中**: 「音声を文字起こししています...」トースト通知
- **プロンプト生成中**:
  - スピナーアニメーション
  - 「AIがプロンプトを生成しています...」メッセージ
- **完了時**: 「プロンプトを生成しました！」成功トースト

### 追加コンテキスト入力

- プロンプト生成前に特定の要件を追加可能
- プレースホルダー: 「プロンプトに含めたい特定の要件や重視すべきポイントを記載してください」
- 任意入力（空でも生成可能）

---

## バリデーション

### リクエストバリデーション

```typescript
const GeneratePromptSchema = z.object({
  audio: z.string().min(1, 'Audio data is required'),
  prompt_type: z.enum(['connected', 'reception']),
  additional_context: z.string().optional(),
})
```

### クライアント側バリデーション

- マイクアクセス許可チェック
- 録音時間制限（最大5分）
- 空の音声データチェック

---

## エラーハンドリング

### エラーコード一覧

| コード                 | HTTPステータス | 説明                                                       |
| ---------------------- | -------------- | ---------------------------------------------------------- |
| `UNAUTHORIZED`         | 401            | 認証が必要です                                             |
| `VALIDATION_ERROR`     | 422            | 入力データが不正です（Zod エラー詳細を含む）               |
| `OPENAI_AUTH_ERROR`    | 500            | OpenAI APIの認証に失敗しました                             |
| `OPENAI_RATE_LIMIT`    | 429            | OpenAI APIのレート制限に達しました                         |
| `INTERNAL_ERROR`       | 500            | プロンプト生成中にエラーが発生しました                     |

### ユーザーフレンドリーなエラーメッセージ

- **マイクアクセスエラー**: 「マイクへのアクセスに失敗しました」
- **最大録音時間超過**: 「最大録音時間 300秒に達しました」
- **API呼び出しエラー**: 具体的なエラーメッセージをトースト表示

---

## 技術的ハイライト

### 1. Web Audio API の活用

```typescript
const stream = await navigator.mediaDevices.getUserMedia({ audio: true })
const mediaRecorder = new MediaRecorder(stream)

mediaRecorder.ondataavailable = event => {
  if (event.data.size > 0) {
    chunksRef.current.push(event.data)
  }
}

mediaRecorder.onstop = async () => {
  const audioBlob = new Blob(chunksRef.current, { type: 'audio/webm' })
  // Base64変換
  const reader = new FileReader()
  reader.onloadend = () => {
    const base64 = reader.result as string
    onRecordingComplete(audioBlob, base64)
  }
  reader.readAsDataURL(audioBlob)
}
```

### 2. Whisper API 連携

```typescript
const audioFile = new File([audioBuffer], 'audio.webm', {
  type: 'audio/webm',
})

const transcription = await openai.audio.transcriptions.create({
  file: audioFile,
  model: 'whisper-1',
  language: 'ja',
})
```

### 3. GPT-4o システムプロンプト設計

```typescript
const systemPrompt = `あなたは営業通話分析AIのプロンプトエンジニアです。
ユーザーが録音した音声から、営業フィードバック生成用のプロンプトを作成してください。

プロンプトタイプ: ${promptTypeLabel}

要件:
1. 文字起こしされたテキストから、ユーザーが求める分析の要点を抽出する
2. 営業通話の文字起こしテキストを分析し、建設的なフィードバックを生成するためのプロンプトを作成する
3. プロンプトは具体的で、AIが理解しやすい形式にする
4. 以下の観点を含める:
   - 分析すべきポイント（話し方、ヒアリング、提案力、クロージングなど）
   - フィードバックの形式（段落構成、項目など）
   - 重視すべき要素
5. プロンプトは日本語で記述する
6. マークダウン形式で構造化する`
```

### 4. リアクティブなUI更新

```typescript
const [generatingPrompt, setGeneratingPrompt] = useState(false)
const [transcription, setTranscription] = useState('')

const handleRecordingComplete = async (_audioBlob: Blob, audioBase64: string) => {
  setGeneratingPrompt(true)

  try {
    toast.info('音声を文字起こししています...')

    const res = await fetch('/api/prompts/generate', {
      method: 'POST',
      headers: { 'Content-Type': 'application/json' },
      body: JSON.stringify({
        audio: audioBase64,
        prompt_type: promptType,
        additional_context: additionalContext || undefined,
      }),
    })

    const data = await res.json()

    setTranscription(data.data.transcription)
    setContent(data.data.generated_prompt)

    toast.success('プロンプトを生成しました！')
  } finally {
    setGeneratingPrompt(false)
  }
}
```

---

## セキュリティ考慮事項

### 認証

- 全APIエンドポイントでSupabase認証チェック
- 未認証ユーザーは401エラー

### データバリデーション

- Zodスキーマによる厳格な入力検証
- Base64データの妥当性チェック

### レート制限

- OpenAI APIのレート制限エラーを適切にハンドリング
- ユーザーフレンドリーなエラーメッセージ表示

### プライバシー

- 録音データはサーバー側で一時的に処理され、永続化されない
- 文字起こし結果はクライアント側のステートのみに保持

---

## パフォーマンス最適化

### クライアント側

- **Dynamic Import**: MDEditorを動的インポートしてSSRを無効化
- **Cleanup処理**: useEffectでメディアストリームとタイマーを適切にクリーンアップ
- **最適化された再レンダリング**: useState + useRefでパフォーマンス最適化

### サーバー側

- **ストリーミング処理**: 音声データをメモリ効率良く処理
- **エラー早期リターン**: バリデーションエラーで早期リターン
- **ログ出力**: 各ステップでログ出力して問題追跡を容易化

---

## テスト項目（今後実装）

### 単体テスト

- [ ] AudioRecorder - 録音開始/停止
- [ ] AudioRecorder - 最大録音時間制限
- [ ] AudioRecorder - Base64変換
- [ ] /api/prompts/generate - バリデーション
- [ ] /api/prompts/generate - Whisper API連携
- [ ] /api/prompts/generate - GPT-4o連携

### 統合テスト

- [ ] 音声録音 → 文字起こし → プロンプト生成 → 保存フロー
- [ ] エラーハンドリング（マイクアクセス拒否）
- [ ] エラーハンドリング（OpenAI APIエラー）

### E2Eテスト

- [ ] ユーザーがAIアシスタントでプロンプトを生成
- [ ] 生成されたプロンプトを編集して保存
- [ ] 追加コンテキストを含むプロンプト生成

---

## 既知の制限事項

### 1. GPT-5未対応

現在はGPT-4oを使用しています。GPT-5がリリースされたら移行する必要があります。

```typescript
// 現在
model: 'gpt-4o'

// GPT-5リリース後
model: 'gpt-5'
```

### 2. ブラウザ互換性

Web Audio APIを使用しているため、以下のブラウザで動作します：

- ✅ Chrome/Edge (推奨)
- ✅ Firefox
- ✅ Safari (iOS 14.3+)
- ❌ IE11（未サポート）

### 3. 録音形式

WebM形式で録音されますが、Safari では一部制限があります。将来的にはMP3やWAVへの変換が必要かもしれません。

### 4. 音声プレビューのみ

現在は録音後のプレビュー再生のみ対応。録音中のリアルタイム音量メーターなどは未実装です。

---

## 次のステップ

### Phase 2 完了

M2.3の完了により、Phase 2（プロンプト管理）が全て完了しました：

- ✅ M2.1: プロンプト管理UI
- ✅ M2.2: プロンプトバージョン管理
- ✅ M2.3: AIプロンプトアシスタント
- ✅ M2.4: フィードバック生成実装

### Phase 3: トークスクリプト管理

次のフェーズでは、トークスクリプト管理機能を実装します：

1. **M3.1: トークスクリプト管理UI** - フェーズ別入力フォーム、ヒアリング項目管理
2. **M3.2: PDF取り込み機能** - GPT-5 Vision APIでPDF→テキスト抽出
3. **M3.3: トークスクリプト一致率分析** - GPT-5でセマンティック一致率評価
4. **M3.4: 因果関係を考慮したフィードバック統合** - ヒアリング不足/提案力不足/クロージング不足の判定

---

## まとめ

M2.3の実装により、プロンプト作成が大幅に簡単になりました。ユーザーは理想的な営業通話を音声で録音するだけで、AIが自動的に最適なフィードバック生成プロンプトを作成します。これにより：

✅ **手動プロンプト作成の負担軽減**: 音声録音だけで完了
✅ **高品質なプロンプト生成**: GPT-4oの強力な言語理解能力を活用
✅ **柔軟なカスタマイズ**: 追加コンテキストで要件を追加可能
✅ **直感的なUI**: 折りたたみ可能なカードでシンプルなワークフロー
✅ **エラーハンドリング**: ユーザーフレンドリーなエラーメッセージ

Phase 2が完了し、次はPhase 3（トークスクリプト管理）に進みます。トークスクリプトとの一致率分析により、より具体的で actionableなフィードバックを生成できるようになります。

---

**作成日**: 2025-01-05
**最終更新**: 2025-01-05
